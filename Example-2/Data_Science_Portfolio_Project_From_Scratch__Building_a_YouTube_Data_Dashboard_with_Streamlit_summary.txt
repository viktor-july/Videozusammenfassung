[0:00:00] Today we're going to build an interactive dashboard, like one that you could share in your portfolio for prospective employers. Rather than just going through the tutorial on its own, I'm going to explain how I would approach the problem and highlight the things that employers will be looking for in your work. The data we're using is from my own YouTube channel, but you could do this with any social data that you have access to.
[0:00:37] The success of dashboards or other digital products is evaluated by the business  value and the impact that they can drive. This is especially true for an interactive product like  a dashboard. We'll be using Python, Plotly, and Streamlit to build this dashboard.
[0:01:14] The video is part of the 66 Days of Data series. The series is designed to help you improve your dashboarding skills and build out your portfolio. More details on that in the description of the video. For more information on the 66 days of data, visit:Â http://66daysofdata.com/.
[0:01:50] YouTubers are also probably looking  to understand new video ideas. Understanding what people are looking for could also be useful. They might also want to keep up to date with how their new videos are performing against  a baseline to see where they should tweak things. If their YouTube content is for profit, they might  want to understand which topics earn the most income.
[0:02:26] The final dashboard will look like. It isn't too fancy. This is just setting the groundwork for you to be able  to build on it. So what I start with is the overall channel aggregated health. So I'm looking at the  performance in the last six months versus a baseline.
[0:03:17] The 80th percentile is how the current video performed over the first 30 days, which is usually how I evaluate if a video is going to be successful. It's also pretty cool to  see the comparison of the video over time. And that's just to say that an individual  project, right, is it's not super straightforward. We have to Google a lot.
[0:04:11] The first thing I recommend that everyone do is to create a  clean environment for us to do this project in. This is something I do for all my projects. It helps me organize what packages I'm working with, what versions I'm using. It also helps when we're actually putting this dashboard into production on GitHub. We have to have the specific versions of all the libraries that we're going to be using.
[0:05:01] Anaconda is a way that  you can encapsulate all of your Python and all the different libraries and versions into a nice  simple place. So this helps us do that really easily. We're going to open this environment and do Python equals 3.8. So I'm going  to go  into my documents and then I think I made a YouTube dashboard streamlet folder.
[0:06:03] This is just going to install the base packages for the kind of environment. What's going to be most relevant here is PIP. So we're  going to use PIP to install pretty much everything else. We want to install a streamlet. We're also going to installed Plotly and that should be everything that  we need.
[0:07:10] You can also just take the requirements file that I create in the GitHub repo and use that to create a new environment. I should probably also make a YAML file that will allow you  to do that directly in Conda but we'll see if I get around to it. Okay. So after you install  streamlet you can do streamlet and then check the version and it shows that it's installed. Now we also want to PIP install Plotly. That's the main visualization software that we're going  to be using here.
[0:08:11] You can download all of  this information here. We're going to load this into the correct file location. So for me,  it's going to be in my documents. And I created this YouTube dashboard so we can open this up and I'll just drag and drop those in.
[0:09:19] We're going to put  this into the YouTube dashboard streamlet and now we can get started. The first thing we want to  do is load in all of the relevant libraries. Rather than typing this out, I'm just going to  copy and paste. Save you some time,
[0:10:16] We're going to use pandas to do all of our data manipulation. We're also going to include plotly graph objects, which is a version of plotly that is highly customizable. NumPy helps you work with different types  of arrays, different data structures.
[0:11:07] We're not going to define  any functions yet, but let's also load in some of our data. So we have four different data sets that  we're going to include.  import streamlet, which is how we're hosting our dashboard. And finally, we're including date time.
[0:12:01] This is which rows you want. This is which columns you want, and for me, this was the easiest way to do that.  skipped the first row and included everything else. So now if we reload it again,  we can see that the total row has been removed. So that's all pretty easy. I also wanted to  get some additional data, which is this DF ag sub.
[0:13:10] There's a couple things that I did with the aggregated data. And let me just copy and paste those and walk through them. In this step, I thought it would be relevant to do just  a little bit of feature engineering. So let's talk about those.
[0:13:57] In the current data set, the publish time is in a string or it's just like an object. If we want  to make it most useful to us, we convert it to a date time value. So date time values mean that we  can take a publish time and we can turn it into, we can sort by that. We can get a date difference.
[0:14:50] The new time field is going to make  that time field a lot more useful and relevant to our analysis. I also did something very similar  with average view duration. This was just like a string timestamp and we converted it using again,  date time into like a time field.
[0:15:45] The last engineering we really did was taking date, taking date. We just take all the different types of engagement and divide it by the views. Same with the views  and sub gained, we take the number of views and divide them by the subscribers gain. What I found is that these were actually just terrible metrics and didn't tell me anything,  aside from that when I had really popular videos that reviewed a lot, the ratios were really low.
[0:16:30] Lambda function is something I use very frequently for some  light feature engineering. We just need to make sure that it is not a string  and it is put into date time and pandas has built in date time. This date time that we use up here is used just a little bit differently.
[0:17:34] When we use a Lambda function, we apply, well, what apply does that it applies whatever function  you pass it to this, to every single row or entry in this series. So we have Lambda X and the function is applied on X. We  just take the date time and we strip time. And then we convert the daytime into this format.
[0:18:30] We're going to create essentially a function that reads in  this data. This is going to make it a lot easier for us to work with this in Streamlabs. We're  going to just put all of this into a function. And then what we are going to return is just the data sets that we created.
[0:19:31] Streamlet has this great,  I guess, system in place where you can cache the data. All the data, we just run this function and it goes through all of this. And so now if we wanted to run the dashboard and have it update, it would work  perfectly fine for that.
[0:20:26] We're going to run Ken Dashboard.py. We have to change our directory as well. So when we run this, we'll get to see what the base Streamlet dashboard looks like. And I will just drag and drop. This should pop up automatically.
[0:21:36] The line of code is going to be fairly straightforward here. So we're going to add in a sidebar and you can get all this  information on the Streamlet documentation. And then the two options are going  to be aggregate metrics and individual video analysis.
[0:22:25] Let's take a quick look at the  actual dashboard. So we want to get the median metrics over time for the channel. And, you know,  we also want to compare that against a baseline. So let's do a little future engineering to try to figure that out.
[0:23:31] The most recent video I published was January 17th. It isn't useful in my opinion to look at  the medians of the data or the differential of thedata from the entire history of the channel. So what we're going to do here is going to take like a 12 month time window.
[0:24:27] We're going to take 12 months minus  that and get a number. And then you can see what this number equates to. So this number here is exactly one year previous to that. Now, what we want to do is get the median for all of the values.
[0:25:38] We're going to create this median aggregate that's just going to get the median for every  single column. We want to take only the last 12 months. We're  going to filter the data frame for only dates that are greater than January 17th, 2021. So if we run that, let's see what it looks like.
[0:26:43] We can take the numpy array and then we look at the data types. If they're equal to float, or this means or in computer language, or if they're an int,  then we'll include them as true, otherwise they'll be false. So if we run numeric columns, we'll just get this giant list of trues and falses.
[0:27:51] The metrics are really unique and cool component of Streamlite dashboards. You can have these at the top and you also can incorporate a delta. So in this case, the delta  shows the percent change in all of these aggregate metrics that are relevant for the last six months  compared to the last year.
[0:28:49] We're going to show you how to make it so that these  aggregate metrics and the individual video analysis, they show just different things when you  toggle them on and off. So  this is how you just write to the page in Streamlite. Let's just say aggregate. We'll just say ag. And then if we say if, and then we'll just do for the second one, if add sidebar equals  these individual videoAnalysis.
[0:30:19] We have end for individual and ag for aggregate. So in those if statements, we can just write  whatever we want. And as long as that specific  metric is selected here,  we can change it well. It just makes it so that you can switch through whatever is being shown on your dashboard very easily.
[0:31:12] We're going to have views, likes, subscribers,  shares, comments added, RPM, which is how much money you make per a thousand views,  average percentage views, average view duration in seconds, engagement ratio,  and views versus subs gained. So these are all of the metrics that I find most relevant,  basically in descending order.
[0:32:09] The most recent six month date range is. directly correlated with channel growth and people actually enjoying the videos that I'm putting out. So we're just going to take the median  of when this time period is in the past six months. And then we're going to create this metric here, which is the aggregate of all of the medians.
[0:33:04] The most recent video was January 17th. So because July 17th would be the six  months previous, that looks correct. And now this one, we can just see what the medians of all the  values are for just that period. So this is what we're seeing.
[0:34:11] The first thing we can do is we can essentially just do that. If we want, we can also include the values. So actually we put the label here first, which would be views. So  and then the value  would be that. So let's see what that looks like here.
[0:35:24] Streamlit allows you to organize metrics in five different ways. If you didn't have the columns, all of the metrics would  just run straight down, which we wouldn't want. We want them to be shown across. That's how I was able to, again,  organize all of these metrics in a row.
[0:36:17] The code is based on some Stack Overflow code. It shows that you don't necessarily have to understand exactly how everything works for it to be functional in your code. The delta is a list that I've created of the columns and put all of the metrics in.
[0:37:03] We're going to use the delta and the delta is going to be formatted. So it is a percent  and only two decimal places. And so that delta, that percent changes what we're putting in here. So we continue to go through. And the reason I added this count logic is probably is not the most elegant way to do this.
[0:37:57] This is  relatively easy to do, but the color formatting took me a lot longer than I would have thought. And so I got to experiment with how to how to do that in pandas. I'm going to show you what I did,
[0:38:52] This is something that took me a lot of time to figure out. So let's get started. So if we want to actually just add the data frame in,  it's going to be really, really easy. So we don't want all of the data. We just want a couple of the different  columns.
[0:40:00] All of our data located here. What I adjusted with published date before, it would show the  format and date time. So there would be all the timestamps and stuff, which would be really messy. What we care about is the published date. All we did was just trim out all of the time information.
[0:41:04] Panda's documentation shows how to format a data frame. The first column is going to be the video title. The second column, technically, is the video name. The third column is the title of the video, and the fourth is the name of the song.
[0:41:59] The apply map feature allows you to format specific things or format all of the different individual data points. And we can pass a function into that. So the first is style negative. So for the value, if it is less than  zero, we will be able to pass something into it. And same here, if the value is greater than zero,  we'll be able  pass in some style formatting. And you know, the interesting thing here  is that we can also throw a try and accept statement.
[0:43:01] This is maybe like a little bit of a janky way to get around the  text columns versus the continuous columns. So what we can do here is we can just  apply map and then we'll do pass our style negative. And then the props is the parameters that we can pass in and we want to color these red.
[0:44:18] All the negative values are red. So now we just want to make all the positive values green. And again, generally with visuals, you don't want to use red and green to be sensitive of colorblind people. In this case,  the metrics have built in red andGreen.
[0:45:48] This was so much harder than I thought it would be. We are going to create a new dictionary. And for each of these columns, we are just going to format them individually. And I'll be honest with you guys, this was probably the hardest part  of this entire project.
[0:46:50] So if we look at this dictionary, we will see that there is this function format string in each of these, right? And now we just have to define one more function, or we have to just add to the  format this dictionary. So we are going to format and pass this dictionary in.
[0:47:57] This is a really useful high level look at what videos really hit and which ones didn't. A video  why everyone should start a podcast, including you, one of my favorite videos to make, but just  absolutely brutalized in terms of the numbers associated with that.
[0:48:59] The US and India are two of the biggest audiences that  I have. And then the other are all effectively around the same proportion. So this is actually  broken up by each individual country. And as you can see, the next biggest one in comparison is  maybe half the size at best.
[0:49:59] We're going to create a select box. We want it to say to be titled or have next to it  is like what the text is. And in order for this to work, we have to include a  tuple of all the different videos. So maybe it would be video one,  video two, etc.
[0:51:07] We're going to want to get the list of all of our videos in here instead. And one of the  challenges is that we have to put it in that tuple format, right? So what that looks like here is that now they're all in parentheses, basically.
[0:52:13] The data scientist creates a bar chart based on the video select variable that was selected. The bar chart can then be used to filter the video title based on that variable. The data scientist uses both the ag filter data and the other data frame to create the bar chart.
[0:53:11] The DF ag sub data frame,  and the same video title column is in there as well. So we can use this and filter this data in the exact same way. And we're going to  filter this by a new function that we create. And that function is just basically going to split things into us, India, or other.
[0:54:07] These are the three biggest categories that I thought were most easy to digest visually. So when we use apply, we can just pass the function  in which is the function we just described. It is a very simple if, Ellis, LF and else, where if the  country code is US, it returns USA. If it's India, it returning India. And if it's anything else,  it returns other.
[0:55:03] We're going to use plotly  express, which I think is really easy to use. We want this to be a horizontal bar chart. So on the x axis,  it's going to be the views on the y. And the color is going  to be  the country that I just defined here.
[0:55:50] The figure is passed into a streamlet. The streamlet has compatibility with basically  every every visualization tool that I've used in Python, which is unbelievable. So we've defined this figure, we pass the figure into  streamlet plotly, and then now it will show up.
[0:56:59] Ken: I think this is pretty interesting is understanding  which videos appeal to different audiences. So maybe my let's see how I learned to learn video.  This one's a pretty good balance. Whereas there are some other videos, like let's say is data science dying, where the  vast majority is viewed by non subscribers.
[0:58:00] The 20th percentile and the 80th percentile all in the first 30 days. So there's a couple steps that  we need to take to be able to organize this data in the appropriate way. So we have to join two data frames together. So let's just real quickly post some code in.
[0:59:03] The number of days since the video is published is the current date minus the video  publish time. And then we convert this into days. That is what the daytime days does there. Now the next thing we're going to do is to create a 12 month moving window,  just like we did before. So what is 12 months since the previous maximum?  We've done this with everything.
[0:59:58] We're going to create this data frame where we're only using  these 12 month moving windows. Next, we're going  to create a pivot table. I prefer pivot tables over  group by that just says for each day in the first 30, what, you know, how many views does a video  get on average?
[1:01:00] "I edit them and then I release them and I watched them a couple of times. You have to do that for sponsors. A lot of the time they want to make sure the  documentation is right" "As you can see, all the views and the relevant metrics are very,  very negligible"
[1:01:58] We want to see not just how many are additional each day, but the running total of each day. And we do this by getting  views. We're going to use the cum sum. And just like we've done before, we're only going to do it on the numeric columns. So we care about median,  80% and 20th percentile.
[1:03:11] We're going to  use Plotly again. It's just going to be a little bit different here. Okay, so we filtered for the first 30 days above just to  get the median 80th percentile and 20th percentile values. All right, now we can start building our last chart here.
[1:04:11] We're going to do go figure. So this  creates a Plotly graph objects figure. Next, in this case, we are going to add an individual line  to it. So the type of chart we'regoing to use is a scatter chart. So it's going to connect the dots.
[1:05:12] After 30 days, the 20th percentile video is looking at  around 2794 likes. So we're just going to add two more traces. This one is going to be the median  views, which is 50th percentile. We're going to show it as a line. So if we didn't want,
[1:06:27] The name is 50th percentile. We're using black as the color. And then for 80th percentile, we're using blue, uh, with dashes again. Uh, that's something I'm obviously going to remove,  but it just shows you how customizable this is, which is pretty neat.
[1:07:27] We're also going to be using views and the cumulative sum of the views here. So we could have done it up here. I thought it was fine to just do it down here instead. And then now when I reload it,  we should be able to see how the video is trending.
[1:08:19] The only data explanation that needs doing pretty well in this  period of time. Is there something actionable I could do to, to make an adjustment  to this in somewhat real time? I definitely check that one out. If, if you're looking for a good high level  explanation of data science, the last thing we're going to do is we're just going to format this a bit nicer.
[1:09:13] This is a pretty like straightforward dashboard that conveys a lot of information to me as a creator. Obviously this is something you could 100% expand upon. I did virtually no  formatting of the graphs. I don't know too many  places where the USA is depicted as green. You know, India, the color probably isn't like way, way off.
[1:10:05] There's plenty of opportunities to make this  your own, to expand upon this. There's also themes in Streamlit. So you could make it like  a dark theme or spice this up in terms of a color palette quite a bit. You know,  this is just scratching the surface of what is possible.
[1:10:50] GitHub allows you to create interactive web platforms without having to do too much complicated work. You can take graphs that you've built somewhere else and make them into something that's very visual and interactive almost instantaneously. We're going to show you how to put this online and make this public to everyone.
[1:11:45] The easiest way to do this would be to just create  a new repo and upload it. We are going to, we're going to add a read me  and we don't need a license. So right now we have this YouTube dashboard here. I'm going to go in.  I'll fill in the, the read me later, but I'mgoing to add some files.
[1:12:49] Pip freeze lets Streamlit know all of the libraries that we're using and what versions they're in. We do have to add one additional file, which is the requirements file. So we're going to do pip freeze and we'regoing to do a caret that way. And this end type require.
[1:13:59] We're going to be doing Ken dashboard. We want this to be Python version 3.8 because that's the version we'll be using. So we uploaded the requirements dot TXT file. There's a few things like the, that are related to Windows. Those aren't relevant.
[1:15:12] The dashboard is live. We can click around and see what's trending. All the code is available. I'd love to see what you guys do. If you build a dashboard  related to this data and you share it with me, I'm happy to forward it along. Hopefully that'll help you understand what goes into a project.
[1:16:00] As usual, thank you so much for watching and good luck on your data science journey. help you